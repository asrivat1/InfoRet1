HW1 by Akshay Srivatsan


Notes on Part 1:
================

This program is to be run through Weka. Upon running hw1a.prl, you will see the file fullstop_data.arff appear. Run this file through Weka using the following options: J48 -C 0.25 -M 2

In my own testing, I got the following results from 10-fold cross validation on the provided training data:

=== Summary ===

Correctly Classified Instances       44930               99.8444 %
Incorrectly Classified Instances        70                0.1556 %
Kappa statistic                          0.9907
Mean absolute error                      0.0025
Root mean squared error                  0.0385
Relative absolute error                  1.5262 %
Root relative squared error             13.348  %
Total Number of Instances            45000     

=== Detailed Accuracy By Class ===

                TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                0.999     0.009      0.999     0.999     0.999      0.999    EOS
                0.991     0.001      0.992     0.991     0.992      0.999    NEOS
Weighted Avg.   0.998     0.008      0.998     0.998     0.998      0.999

=== Confusion Matrix ===

    a     b   <-- classified as
40844    33 |     a = EOS
37     4086 |     b = NEOS


Notes on Part 2:
================

This program is to be run through Weka. Upon running hw1a.prl, you will see the file cat_data.arff appear. Run this file through Weka using the following options: RandomForest -I 100 -K 0 -S 1

In my own testing, I got the following results from 10-fold cross validation on the provided training data:

=== Summary ===

Correctly Classified Instances         926               94.1057 %
Incorrectly Classified Instances        58                5.8943 %
Kappa statistic                          0.9133
Mean absolute error                      0.0286
Root mean squared error                  0.1063
Relative absolute error                 18.6952 %
Root relative squared error             38.4563 %
Total Number of Instances              984     

=== Detailed Accuracy By Class ===

TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
1         0          1         1         1          1        NNHEAD
0.971     0.007      0.966     0.971     0.969      0.999    QUOTED
0.901     0.013      0.842     0.901     0.871      0.995    SIG
0.793     0.002      0.92      0.793     0.852      0.998    TABLE
0.556     0          1         0.556     0.714      0.995    GRAPHIC
0.864     0.003      0.927     0.864     0.894      0.984    HEADL
0.727     0.001      0.889     0.727     0.8        0.997    ADDRESS
0.577     0.003      0.833     0.577     0.682      0.939    ITEM
0.968     0.064      0.94      0.968     0.954      0.987    PTEXT
Weighted Avg.    0.941     0.035      0.941     0.941     0.939      0.99 

=== Confusion Matrix ===
  a   b   c   d   e   f   g   h   i   <-- classified as
120   0   0   0   0   0   0   0   0 |   a = NNHEAD
  0 170   0   0   0   0   0   0   5 |   b = QUOTED
  0   0  64   0   0   0   0   0   7 |   c = SIG
  0   0   0  23   0   0   0   1   5 |   d = TABLE
  0   0   2   2   5   0   0   0   0 |   e = GRAPHIC
  0   0   0   0   0  38   1   0   5 |   f = HEADL
  0   1   1   0   0   1   8   0   0 |   g = ADDRESS
  0   1   0   0   0   1   0  15   9 |   h = ITEM
  0   4   9   0   0   1   0   2 483 |   i = PTEXT
